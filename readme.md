# MicroLearn â€” Orchestrateur AutoML par microservices  

> **Projet acadÃ©mique** â€“ Plateforme AutoML distribuÃ©e par microservices, dÃ©veloppÃ©e en mode startup par une Ã©quipe de 4 personnes.  
> Objectif : automatiser et orchestrer le cycle complet de Machine Learning (prÃ©paration â†’ sÃ©lection â†’ entraÃ®nement â†’ Ã©valuation â†’ dÃ©ploiement) via API et dashboard web.  

---

Azure devops: https://dev.azure.com/SoulaimaneOuhmida/MicroLearn

---

## ğŸ“˜ Sommaire

1. [ğŸ¯ Objectif du projet](#-objectif-du-projet)  
2. [ğŸ—ï¸ Architecture & Microservices](#ï¸-architecture--microservices)  
3. [ğŸ‘¥ Organisation de lâ€™Ã©quipe](#-organisation-de-lÃ©quipe)  
4. [ğŸ’¡ User Stories](#-user-stories)  
5. [ğŸ“ Structure du projet](#-structure-du-projet)  
6. [ğŸ§© Technologies & Outils](#-technologies--outils)  
7. [âš™ï¸ Installation & ExÃ©cution](#ï¸-installation--exÃ©cution)  
8. [ğŸ§ª Tests & QualitÃ©](#-tests--qualitÃ©)  
9. [ğŸ“… Planning & MÃ©thodologie Agile](#-planning--mÃ©thodologie-agile)  
10. [ğŸ“ PrÃ©sentation finale](#-prÃ©sentation-finale)  
11. [ğŸ“ Contacts encadrants](#-contacts-encadrants)

---

## ğŸ¯ Objectif du projet

**MicroLearn** vise Ã  automatiser le processus de Machine Learning grÃ¢ce Ã  une **architecture microservices**.  
Chaque Ã©tape du cycle ML (de la prÃ©paration des donnÃ©es au dÃ©ploiement du modÃ¨le) est encapsulÃ©e dans un microservice indÃ©pendant, communiquant via **REST APIs** et **NATS (event bus)**.  

### Objectifs principaux :
- Composer et exÃ©cuter des pipelines AutoML dÃ©finis en YAML.  
- SÃ©lectionner, entraÃ®ner, optimiser et Ã©valuer automatiquement plusieurs modÃ¨les ML.  
- Fournir un **dashboard React** pour visualiser runs, mÃ©triques et modÃ¨les dÃ©ployÃ©s.  
- Offrir une architecture **scalable, reproductible et modulaire**.  

---

## ğŸ—ï¸ Architecture & Microservices

### ğŸ§© SchÃ©ma global  
```
DataPreparer â†’ ModelSelector â†’ Trainer â†’ Evaluator â†’ Deployer  
                      â†‘                 â†“  
                 HyperOpt â† Orchestrator â†’ Dashboard
```

| Microservice | Stack principale | Description |
|---------------|------------------|--------------|
| **DataPreparer** | FastAPI + Pandas + PostgreSQL + MinIO | Upload et nettoyage des datasets |
| **ModelSelector** | Scikit-learn + PyCaret | SÃ©lection automatique de modÃ¨les adaptÃ©s |
| **Trainer** | PyTorch Lightning + Ray + MLflow | EntraÃ®nement parallÃ¨le et suivi des runs |
| **HyperOpt** | Optuna + Redis + FastAPI | Optimisation des hyperparamÃ¨tres |
| **Evaluator** | Scikit-learn + Plotly | Calcul et visualisation des mÃ©triques |
| **Deployer** | TorchServe + Flask + Docker | DÃ©ploiement des modÃ¨les via API REST |
| **Orchestrator** | Node.js + NATS + Redis | ExÃ©cution asynchrone de pipelines YAML |
| **Dashboard** | React + D3.js + Chart.js | Interface visuelle pour runs et mÃ©triques |

---

<!-- ## ğŸ‘¥ Organisation de lâ€™Ã©quipe

| RÃ´le | Nom | ResponsabilitÃ©s principales |
|------|------|-----------------------------|
| **Tech Lead / Architecte** | Personne A | Architecture microservices, orchestrateur, API Gateway, CI/CD |
| **Data & ML Engineer** | Personne B | ModelSelector, Trainer, HyperOpt, MLflow |
| **Full-Stack & DevOps** | Personne C | Dashboard React, Docker, MinIO, PostgreSQL |
| **MLOps & QA / Documentation** | Personne D | Tests, Postman, SonarQube, Selenium, documentation, Trello |

Chaque membre livre un microservice **fonctionnel avec API, tests et documentation**. -->

---

<!-- ## ğŸ’¡ User Stories

| ID | User Story |
|----|-------------|
| **US01** | En tant que Data Scientist, je veux uploader un dataset et nettoyer les donnÃ©es. |
| **US02** | Je veux dÃ©finir un pipeline de preprocessing via YAML. |
| **US03** | Je veux obtenir une liste de modÃ¨les automatiquement sÃ©lectionnÃ©s. |
| **US04** | Je veux entraÃ®ner plusieurs modÃ¨les en parallÃ¨le. |
| **US05** | Je veux optimiser les hyperparamÃ¨tres automatiquement. |
| **US06** | Je veux comparer les performances des modÃ¨les. |
| **US07** | Je veux dÃ©ployer le meilleur modÃ¨le via API. |
| **US08** | Je veux visualiser les mÃ©triques et rapports sur le dashboard. | 

--- -->

<!-- ## ğŸ“ Structure du projet

```
ğŸ“¦ MicroLearn/
 â”£ ğŸ“ services/
 â”ƒ â”£ ğŸ“ data-preparer/
 â”ƒ â”£ ğŸ“ model-selector/
 â”ƒ â”£ ğŸ“ trainer/
 â”ƒ â”£ ğŸ“ evaluator/
 â”ƒ â”£ ğŸ“ hyperopt/
 â”ƒ â”£ ğŸ“ deployer/
 â”£ ğŸ“ orchestrator/
 â”£ ğŸ“ dashboard/
 â”£ ğŸ“ docs/
 â”£ ğŸ“œ docker-compose.yml
 â”£ ğŸ“œ README.md
```

--- -->

## ğŸ§© Technologies & Outils

| CatÃ©gorie | Outils / Technologies |
|------------|------------------------|
| **Langages** | Python, Node.js, React |
| **Bases de donnÃ©es** | PostgreSQL, Redis |
| **Stockage fichiers** | MinIO |
| **ML & AutoML** | PyCaret, PyTorch Lightning, Optuna, MLflow |
| **Orchestration** | NATS, Ray |
| **Containerisation** | Docker, docker-compose |
| **CI/CD** | GitHub Actions |
| **Tests** | Pytest, Postman/Newman, Selenium |
| **Docs & Tracking** | Swagger, SonarQube, Grafana (optionnel) |
| **Gestion projet** | Trello + Notion (optionnel) |

---

<!-- ## âš™ï¸ Installation & ExÃ©cution

### 1ï¸âƒ£ Cloner le projet
```bash
git clone https://github.com/<user>/MicroLearn.git
cd MicroLearn
```

### 2ï¸âƒ£ Lancer les services
```bash
docker-compose up --build
```

### 3ï¸âƒ£ AccÃ©der aux composants
| Service | URL |
|----------|-----|
| Dashboard | http://localhost:3000 |
| Orchestrator API | http://localhost:8080 |
| MLflow | http://localhost:5000 |
| MinIO | http://localhost:9000 |

--- -->

## ğŸ§ª Tests & QualitÃ©

- **Unit tests** : `pytest` (Python) / `jest` (Node.js)  
- **Integration tests** : via `docker-compose`  
- **API tests** : Postman collection + Newman  
- **End-to-end** : Selenium (UI)  
- **Coverage attendu** : â‰¥ 60%  
- **Lint & QA** : SonarQube, GitHub Actions CI  

---

## ğŸ“… Planning & MÃ©thodologie Agile

| Sprint | DurÃ©e | Objectif |
|---------|--------|-----------|
| **Sprint 1** | 1 semaine | Setup Git, Docker, Trello, base architecture |
| **Sprint 2** | 2 semaines | DataPreparer + ModelSelector + HyperOpt |
| **Sprint 3** | 2 semaines | Trainer + Evaluator |
| **Sprint 4** | 1 semaine | Deployer + Dashboard |
| **Sprint 5** | 1 semaine | Tests, rapport final, prÃ©sentation |

### Trello structure :
- Stories  
- Ã€ faire  
- En cours  
- Tests  
- TerminÃ©  
- ValidÃ© (par prof) âœ…  

ğŸ‘¨â€ğŸ« **Partage du tableau avec** :  
- O.ouedrhiri@emsi.ma  
- H.Tabbaa@emsi.ma  
- lachgar.m@gmail.com  

---

## ğŸ“ PrÃ©sentation finale

### Livrables
- Repos GitHub + Dockerfiles  
- Docs techniques + Swagger/OpenAPI  
- Rapport PDF (5â€“10 pages)  
- DÃ©mo vidÃ©o (5 min)  
- Slides de soutenance  

### Points clÃ©s Ã  dÃ©montrer :
- Architecture microservices  
- Pipeline ML automatisÃ©  
- API documentÃ©es  
- Dashboard visuel  
- Logs & suivi MLflow  
- DÃ©ploiement fonctionnel  

## ğŸ“ Contacts encadrants

| Nom | Email |
|------|--------|
| **O. Ouedrhiri** | O.ouedrhiri@emsi.ma |
| **H. Tabbaa** | H.Tabbaa@emsi.ma |
| **M. Lachgar** | lachgar.m@gmail.com |







âœ… 4 Microservices Architecture (Backend-Only)

Each microservice is independent, containerized, and stateless.

1ï¸âƒ£ Dataset Manager Service

Purpose: Handle datasets lifecycle
Tech: Python (FastAPI) or Node.js
Responsibilities:

Upload CSV/Parquet files

Validate schema

Store dataset metadata (PostgreSQL or MongoDB)

Provide dataset samples/preprocessing preview

Serve datasets to the Trainer service

Core Endpoints:

POST /datasets â€” Upload dataset

GET /datasets/{id} â€” Get dataset metadata

GET /datasets/{id}/sample â€” Return sample rows

DELETE /datasets/{id} â€” Remove dataset

2ï¸âƒ£ Feature & Model Selector Service

Purpose: Automatically select model type + basic preprocessing
Tech: Python (FastAPI), scikit-learn
Responsibilities:

Detect problem type (classification, regression)

Propose candidate models (RandomForest, XGBoost, MLPâ€¦)

Handle auto-feature-engineering

Return a list of models + suggested hyperparameters

Cache model suggestions

Core Endpoints:

POST /select-model â€” Input dataset schema â†’ Output candidate models

GET /models/{id} â€” Retrieve selected models

3ï¸âƒ£ Trainer Service

Purpose: Train models + evaluate them
Tech: Python (FastAPI), PyTorch Lightning, MLflow
Responsibilities:

Receive model type + dataset

Train model

Track metrics (accuracy, RMSE, F1â€¦)

Log experiments via MLflow

Save best model to storage (S3/Azure Blob/MinIO)

Stream training logs

Core Endpoints:

POST /train â€” Launch training job

GET /train/{jobId}/status â€” Job status (QUEUED / RUNNING / DONE)

GET /train/{jobId}/metrics â€” Retrieve metrics

POST /train/{jobId}/stop â€” Stop training

4ï¸âƒ£ Hyperparameter Optimization (AutoML) Service

Purpose: Run Optuna or Hyperopt to optimize hyperparameters
Tech: Python + Optuna
Responsibilities:

Launch optimization loop

Try N models in parallel

Choose best hyperparameters

Return best model configuration

Communicate with Trainer service for each trial

Core Endpoints:

POST /optimize â€” Start HPO session

GET /optimize/{sessionId}/status

GET /optimize/{sessionId}/best