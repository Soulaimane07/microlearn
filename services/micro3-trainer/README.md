# ğŸš€ Trainer - Service d'EntraÃ®nement de ModÃ¨les ML

## ğŸ“‹ Description

**Trainer** est le troisiÃ¨me microservice de la plateforme MicroLearn qui gÃ¨re l'**entraÃ®nement parallÃ¨le** des modÃ¨les de Machine Learning sÃ©lectionnÃ©s. Il supporte l'accÃ©lÃ©ration GPU, l'entraÃ®nement distribuÃ© avec Ray, et le suivi des expÃ©riences avec MLflow.

## ğŸ—ï¸ Architecture

```
trainer/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                          # Point d'entrÃ©e FastAPI
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ health_router.py             # Endpoints de santÃ©
â”‚   â”‚   â”œâ”€â”€ train_router.py              # Endpoints d'entraÃ®nement
â”‚   â”‚   â””â”€â”€ models_router.py             # Endpoints modÃ¨les entraÃ®nÃ©s
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py                    # Configuration
â”‚   â”‚   â””â”€â”€ logger.py                    # Logging
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ request_models.py            # ModÃ¨les de requÃªte
â”‚   â”‚   â””â”€â”€ response_models.py           # ModÃ¨les de rÃ©ponse
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ training_orchestrator.py     # Orchestrateur principal
â”‚   â”‚   â”œâ”€â”€ model_factory.py             # Factory de modÃ¨les ML
â”‚   â”‚   â””â”€â”€ mlflow_tracker.py            # IntÃ©gration MLflow
â”‚   â””â”€â”€ storage/
â”‚       â”œâ”€â”€ minio_client.py              # Client MinIO
â”‚       â””â”€â”€ postgres_client.py           # Client PostgreSQL
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_training.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ requirements.txt
```

## ğŸš€ FonctionnalitÃ©s

### 1. EntraÃ®nement Asynchrone
- Soumission de jobs d'entraÃ®nement en arriÃ¨re-plan
- Suivi en temps rÃ©el de la progression
- Support de l'annulation de jobs en cours

### 2. AccÃ©lÃ©ration GPU
- DÃ©tection automatique des GPU disponibles
- Allocation intelligente des GPUs aux jobs
- Support multi-GPU avec distribution Ã©quitable
- Fallback CPU si pas de GPU disponible

### 3. Gestion des ModÃ¨les
Plus de **20 modÃ¨les** supportÃ©s :
- **Classification** : Random Forest, XGBoost, LightGBM, SVM, KNN, etc.
- **RÃ©gression** : Linear, Ridge, Lasso, Random Forest, XGBoost, etc.
- **Clustering** : K-Means, DBSCAN, Hierarchical

### 4. Suivi avec MLflow
- Journalisation automatique des hyperparamÃ¨tres
- Tracking des mÃ©triques par epoch
- Sauvegarde des artefacts
- Comparaison d'expÃ©riences

### 5. Stockage DistribuÃ©
- **MinIO** : Sauvegarde des modÃ¨les entraÃ®nÃ©s et checkpoints
- **PostgreSQL** : MÃ©tadonnÃ©es, jobs, et mÃ©triques
- TÃ©lÃ©chargement sÃ©curisÃ© des modÃ¨les

## ğŸ“¡ API Endpoints

### SantÃ©
```http
GET /health/
```
VÃ©rifie l'Ã©tat du service et des ressources.

**RÃ©ponse :**
```json
{
  "status": "ok",
  "service": "trainer",
  "gpu_available": true,
  "ray_initialized": false,
  "mlflow_connected": true,
  "postgres_connected": true,
  "minio_connected": true
}
```

### EntraÃ®nement

#### DÃ©marrer un entraÃ®nement
```http
POST /train
```

**Body (JSON) :**
```json
{
  "model_id": "xgboost_classifier",
  "data_id": "dataset_123.csv",
  "task_type": "classification",
  "epochs": 100,
  "batch_size": 32,
  "learning_rate": 0.001,
  "hyperparameters": {
    "n_estimators": 100,
    "max_depth": 6
  },
  "target_column": "target",
  "use_gpu": true,
  "early_stopping": true,
  "patience": 10,
  "experiment_name": "my_experiment",
  "tags": {
    "team": "data-science"
  }
}
```

**RÃ©ponse :**
```json
{
  "job_id": "train_a1b2c3d4e5f6",
  "status": "pending",
  "model_id": "xgboost_classifier",
  "data_id": "dataset_123.csv",
  "created_at": "2025-12-02T10:00:00",
  "total_epochs": 100,
  "mlflow_run_id": "abc123def456"
}
```

#### Obtenir le statut d'un job
```http
GET /train/{job_id}
```

**RÃ©ponse :**
```json
{
  "job_id": "train_a1b2c3d4e5f6",
  "status": "running",
  "model_id": "xgboost_classifier",
  "current_epoch": 45,
  "total_epochs": 100,
  "progress_percentage": 45.0,
  "gpu_allocated": "cuda:0",
  "best_metrics": {
    "val_accuracy": 0.92,
    "train_accuracy": 0.95
  }
}
```

#### Progression dÃ©taillÃ©e
```http
GET /train/{job_id}/progress
```

Retourne les mÃ©triques par epoch et les checkpoints sauvegardÃ©s.

#### Lister les jobs
```http
GET /train?status=running&limit=10
```

**ParamÃ¨tres :**
- `status` : Filtrer par statut (pending, running, completed, failed)
- `limit` : Nombre max de rÃ©sultats (1-100)

#### Annuler un job
```http
DELETE /train/{job_id}
```

### ModÃ¨les EntraÃ®nÃ©s

#### Lister les modÃ¨les
```http
GET /models/?page=1&page_size=10
```

**RÃ©ponse :**
```json
{
  "models": [
    {
      "model_id": "xgboost_classifier",
      "job_id": "train_a1b2c3d4e5f6",
      "model_name": "Xgboost Classifier",
      "task_type": "classification",
      "minio_path": "trained-models/xgboost_classifier/train_a1b2c3d4e5f6_20251202.pkl",
      "file_size_mb": 2.5,
      "metrics": {
        "val_accuracy": 0.92
      },
      "created_at": "2025-12-02T11:30:00"
    }
  ],
  "total": 1,
  "page": 1,
  "page_size": 10
}
```

#### DÃ©tails d'un modÃ¨le
```http
GET /models/{job_id}
```

#### TÃ©lÃ©charger un modÃ¨le
```http
GET /models/{job_id}/download
```

TÃ©lÃ©charge le fichier `.pkl` du modÃ¨le entraÃ®nÃ©.

#### Supprimer un modÃ¨le
```http
DELETE /models/{job_id}
```

## âš™ï¸ Configuration

Variables d'environnement :

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `SERVICE_NAME` | Nom du service | trainer |
| `SERVICE_PORT` | Port d'Ã©coute | 8002 |
| `POSTGRES_HOST` | HÃ´te PostgreSQL | postgres |
| `POSTGRES_DB` | Base de donnÃ©es | microlearn |
| `MINIO_ENDPOINT` | Endpoint MinIO | minio:9000 |
| `MINIO_BUCKET_MODELS` | Bucket des modÃ¨les | trained-models |
| `MINIO_BUCKET_DATA` | Bucket des donnÃ©es | data-preparer |
| `MLFLOW_TRACKING_URI` | URI MLflow | http://mlflow:5000 |
| `MAX_PARALLEL_JOBS` | Jobs parallÃ¨les max | 3 |
| `DEFAULT_EPOCHS` | Epochs par dÃ©faut | 100 |
| `EARLY_STOPPING_PATIENCE` | Patience early stopping | 10 |
| `CUDA_VISIBLE_DEVICES` | GPUs visibles | None (tous) |

## ğŸ³ Lancement

### Avec Docker Compose
```bash
cd microlearn
docker-compose up -d trainer
```

Le service sera accessible sur : `http://localhost:8002`

### Avec GPU (Docker Compose)
DÃ©commentez la section GPU dans `docker-compose.yml` :
```yaml
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: all
          capabilities: [gpu]
```

Puis :
```bash
docker-compose up -d --build trainer
```

### Documentation API
Swagger UI : `http://localhost:8002/docs`

## ğŸ”„ Flux de Travail

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RequÃªte       â”‚â”€â”€â”€â”€â–¶â”‚  Training        â”‚â”€â”€â”€â”€â–¶â”‚  PostgreSQL     â”‚
â”‚   d'entraÃ®nementâ”‚     â”‚  Orchestrator    â”‚     â”‚  (metadata)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Allocation  â”‚
                        â”‚  GPU/CPU     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Chargement  â”‚
                        â”‚  Dataset     â”‚â—€â”€â”€â”€ MinIO (data-preparer)
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Model       â”‚
                        â”‚  Factory     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  EntraÃ®nementâ”‚
                        â”‚  + Metrics   â”‚â”€â”€â”€â”€â–¶ MLflow
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Sauvegarde  â”‚
                        â”‚  ModÃ¨le      â”‚â”€â”€â”€â”€â–¶ MinIO (trained-models)
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Job         â”‚
                        â”‚  Completed   â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“Š Suivi avec MLflow

Le service s'intÃ¨gre avec MLflow pour le suivi des expÃ©riences :

1. **ParamÃ¨tres journalisÃ©s** :
   - model_id, task_type, epochs, batch_size, learning_rate
   - Tous les hyperparamÃ¨tres personnalisÃ©s

2. **MÃ©triques trackÃ©es** :
   - train_loss, val_loss
   - train_accuracy, val_accuracy (classification)
   - train_rmse, val_rmse, val_r2 (rÃ©gression)

3. **Tags** :
   - Tags personnalisÃ©s via l'API
   - job_id, data_id automatiques

## ğŸ§ª Tests

```bash
# Lancer les tests
cd trainer
pytest tests/ -v

# Avec couverture
pytest tests/ --cov=app --cov-report=html
```

## ğŸ“š DÃ©pendances Principales

- **PyTorch** : Framework deep learning avec support GPU
- **PyTorch Lightning** : Simplification de l'entraÃ®nement
- **Ray** : Calcul distribuÃ© et parallÃ©lisation
- **MLflow** : Suivi d'expÃ©riences
- **FastAPI** : API REST
- **scikit-learn, XGBoost, LightGBM** : ModÃ¨les ML
- **MinIO** : Stockage d'objets
- **PostgreSQL** : Base de donnÃ©es relationnelle

## ğŸ”— IntÃ©gration avec MicroLearn

Trainer s'intÃ¨gre avec les autres microservices :

1. **DataPreparer** (port 8000) : Source des datasets nettoyÃ©s
2. **ModelSelector** (port 8001) : Fournit les modÃ¨les recommandÃ©s
3. **Trainer** (port 8002) : EntraÃ®ne les modÃ¨les â† *Vous Ãªtes ici*
4. **Deployer** (Ã  venir) : DÃ©ploiement des modÃ¨les entraÃ®nÃ©s

## ğŸ“ Exemple Complet

```python
import requests

BASE_URL = "http://localhost:8002"

# 1. VÃ©rifier la santÃ©
health = requests.get(f"{BASE_URL}/health/").json()
print(f"GPU disponible: {health['gpu_available']}")

# 2. DÃ©marrer un entraÃ®nement
training_request = {
    "model_id": "random_forest_classifier",
    "data_id": "iris_prepared.csv",
    "task_type": "classification",
    "epochs": 50,
    "hyperparameters": {
        "n_estimators": 100,
        "max_depth": 10
    },
    "target_column": "species",
    "use_gpu": False,
    "experiment_name": "iris_classification"
}

response = requests.post(f"{BASE_URL}/train", json=training_request)
job = response.json()
job_id = job['job_id']
print(f"Job crÃ©Ã©: {job_id}")

# 3. Surveiller la progression
import time
while True:
    status = requests.get(f"{BASE_URL}/train/{job_id}").json()
    print(f"Status: {status['status']}, Progress: {status.get('progress_percentage', 0)}%")
    
    if status['status'] in ['completed', 'failed']:
        break
    
    time.sleep(5)

# 4. RÃ©cupÃ©rer le modÃ¨le entraÃ®nÃ©
if status['status'] == 'completed':
    model_info = requests.get(f"{BASE_URL}/models/{job_id}").json()
    print(f"ModÃ¨le: {model_info['model_name']}")
    print(f"MÃ©triques: {model_info['metrics']}")
    
    # TÃ©lÃ©charger le modÃ¨le
    model_file = requests.get(f"{BASE_URL}/models/{job_id}/download")
    with open(f"{job_id}_model.pkl", "wb") as f:
        f.write(model_file.content)
    print("ModÃ¨le tÃ©lÃ©chargÃ©!")
```

## ğŸ¯ Cas d'Usage

### 1. EntraÃ®nement Batch
EntraÃ®ner plusieurs modÃ¨les en parallÃ¨le pour comparer les performances.

### 2. Hyperparameter Tuning
Lancer plusieurs jobs avec diffÃ©rents hyperparamÃ¨tres et comparer dans MLflow.

### 3. Production Pipeline
IntÃ©grer dans un pipeline CI/CD pour rÃ©entraÃ®ner automatiquement les modÃ¨les.

### 4. ExpÃ©rimentation Rapide
Tester rapidement diffÃ©rents algorithmes sur un nouveau dataset.

## ğŸ› DÃ©bogage

### Logs
```bash
# Logs du conteneur
docker logs trainer -f

# Logs d'erreurs (dans le conteneur)
tail -f /app/logs/trainer_errors.log
```

### ProblÃ¨mes Courants

**GPU non dÃ©tectÃ©** :
- VÃ©rifier `nvidia-docker` installÃ©
- DÃ©commenter la section GPU dans `docker-compose.yml`
- VÃ©rifier `CUDA_VISIBLE_DEVICES`

**MLflow non connectÃ©** :
- DÃ©marrer le service MLflow
- VÃ©rifier `MLFLOW_TRACKING_URI`

**Dataset non trouvÃ©** :
- VÃ©rifier que le fichier existe dans MinIO bucket `data-preparer`
- VÃ©rifier le chemin `data_id`

## ğŸ‘¥ Auteurs

DÃ©veloppÃ© dans le cadre du projet **MicroLearn** - Plateforme AutoML Microservices.

## ğŸ“„ Licence

Ce projet fait partie de MicroLearn - Projet acadÃ©mique 5IIR.
